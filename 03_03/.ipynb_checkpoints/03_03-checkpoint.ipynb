{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caa8cd98",
   "metadata": {},
   "source": [
    "# 03_03: Create a Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b126d991",
   "metadata": {},
   "source": [
    "### Install the necesarry libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "110a4c70-2816-4d07-bb94-734d875f1802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "785f831f-1711-4c78-b5ca-4b258113b79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load and preprocess the dataset\n",
    "data = pd.read_csv('customer_churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f0adff1c-5d6c-4b63-84be-4f7d94cd63c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features and target\n",
    "X = data.drop('churn', axis=1)\n",
    "y = data['churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "884c9a89-8baf-45a1-988f-8225fee37811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aa60dd73-87e8-46ce-9a46-8f4018e0bdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0855ffbb-7db3-45af-98f3-4b9217e4f86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Build the neural network model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(16, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d229347b-f912-403b-b3a9-d727981017f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "20/20 [==============================] - 1s 8ms/step - loss: 0.7174 - accuracy: 0.4594 - val_loss: 0.6833 - val_accuracy: 0.5500\n",
      "Epoch 2/20\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6536 - accuracy: 0.6078 - val_loss: 0.6221 - val_accuracy: 0.6812\n",
      "Epoch 3/20\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6000 - accuracy: 0.7797 - val_loss: 0.5642 - val_accuracy: 0.8750\n",
      "Epoch 4/20\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5473 - accuracy: 0.8906 - val_loss: 0.5088 - val_accuracy: 0.9187\n",
      "Epoch 5/20\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4956 - accuracy: 0.9328 - val_loss: 0.4545 - val_accuracy: 0.9250\n",
      "Epoch 6/20\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4432 - accuracy: 0.9469 - val_loss: 0.3992 - val_accuracy: 0.9375\n",
      "Epoch 7/20\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3922 - accuracy: 0.9578 - val_loss: 0.3459 - val_accuracy: 0.9500\n",
      "Epoch 8/20\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3446 - accuracy: 0.9625 - val_loss: 0.2987 - val_accuracy: 0.9625\n",
      "Epoch 9/20\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3026 - accuracy: 0.9656 - val_loss: 0.2590 - val_accuracy: 0.9625\n",
      "Epoch 10/20\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2663 - accuracy: 0.9672 - val_loss: 0.2250 - val_accuracy: 0.9563\n",
      "Epoch 11/20\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2355 - accuracy: 0.9703 - val_loss: 0.1973 - val_accuracy: 0.9688\n",
      "Epoch 12/20\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2097 - accuracy: 0.9703 - val_loss: 0.1759 - val_accuracy: 0.9688\n",
      "Epoch 13/20\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1888 - accuracy: 0.9703 - val_loss: 0.1591 - val_accuracy: 0.9625\n",
      "Epoch 14/20\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1718 - accuracy: 0.9688 - val_loss: 0.1458 - val_accuracy: 0.9625\n",
      "Epoch 15/20\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1577 - accuracy: 0.9703 - val_loss: 0.1351 - val_accuracy: 0.9625\n",
      "Epoch 16/20\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1467 - accuracy: 0.9688 - val_loss: 0.1264 - val_accuracy: 0.9625\n",
      "Epoch 17/20\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1369 - accuracy: 0.9703 - val_loss: 0.1183 - val_accuracy: 0.9625\n",
      "Epoch 18/20\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1287 - accuracy: 0.9734 - val_loss: 0.1121 - val_accuracy: 0.9625\n",
      "Epoch 19/20\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1214 - accuracy: 0.9719 - val_loss: 0.1066 - val_accuracy: 0.9625\n",
      "Epoch 20/20\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1151 - accuracy: 0.9719 - val_loss: 0.1022 - val_accuracy: 0.9688\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x141cc3dc0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: Compile and train the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7a2773d7-4d13-4566-ab2c-553d7ddbc9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Use the model to make predictions\n",
    "# Make predictions on the test set\n",
    "\n",
    "y_pred_prob = model.predict(X_test)  # Predicted probabilities\n",
    "y_pred = (y_pred_prob > 0.5).astype(\"int32\").flatten()  # Convert probabilities to binary predictions and flatten the array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "67d46262-a59c-4311-b66c-d6cc3c8d452f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted vs Actual values:\n",
      "Index  Predicted     Actual  Probability\n",
      "----------------------------------------\n",
      "    0          0          0         0.01\n",
      "    1          0          0         0.01\n",
      "    2          1          1         0.80\n",
      "    3          0          0         0.04\n",
      "    4          1          1         0.98\n",
      "    5          1          1         0.86\n",
      "    6          0          0         0.16\n",
      "    7          0          0         0.05\n",
      "    8          0          0         0.00\n",
      "    9          1          1         0.69\n",
      "   10          1          1         0.98\n",
      "   11          0          0         0.01\n",
      "   12          0          0         0.03\n",
      "   13          0          0         0.00\n",
      "   14          0          0         0.00\n",
      "   15          1          1         0.90\n",
      "   16          0          0         0.01\n",
      "   17          0          0         0.05\n",
      "   18          0          0         0.01\n",
      "   19          0          0         0.20\n",
      "   20          1          1         0.95\n",
      "   21          0          0         0.01\n",
      "   22          1          1         0.62\n",
      "   23          0          0         0.10\n",
      "   24          0          0         0.00\n",
      "   25          0          0         0.01\n",
      "   26          1          1         1.00\n",
      "   27          0          0         0.00\n",
      "   28          1          1         0.95\n",
      "   29          0          0         0.11\n",
      "   30          0          0         0.06\n",
      "   31          0          0         0.06\n",
      "   32          1          1         0.98\n",
      "   33          0          0         0.27\n",
      "   34          0          0         0.04\n",
      "   35          1          1         0.62\n",
      "   36          0          0         0.11\n",
      "   37          0          0         0.05\n",
      "   38          0          0         0.05\n",
      "   39          1          1         0.79\n",
      "   40          0          0         0.00\n",
      "   41          0          0         0.09\n",
      "   42          1          1         0.90\n",
      "   43          0          0         0.01\n",
      "   44          0          0         0.49\n",
      "   45          0          0         0.02\n",
      "   46          1          1         0.99\n",
      "   47          1          1         1.00\n",
      "   48          0          0         0.03\n",
      "   49          0          0         0.02\n",
      "   50          0          0         0.00\n",
      "   51          0          0         0.06\n",
      "   52          0          0         0.36\n",
      "   53          0          0         0.01\n",
      "   54          0          0         0.02\n",
      "   55          0          0         0.07\n",
      "   56          0          0         0.00\n",
      "   57          1          1         0.83\n",
      "   58          0          0         0.00\n",
      "   59          1          0         0.52\n",
      "   60          0          0         0.02\n",
      "   61          0          0         0.00\n",
      "   62          0          0         0.01\n",
      "   63          0          0         0.00\n",
      "   64          0          0         0.01\n",
      "   65          0          0         0.01\n",
      "   66          0          0         0.02\n",
      "   67          0          0         0.02\n",
      "   68          0          0         0.01\n",
      "   69          1          1         0.73\n",
      "   70          1          1         0.82\n",
      "   71          0          0         0.08\n",
      "   72          0          0         0.21\n",
      "   73          1          1         0.99\n",
      "   74          0          0         0.04\n",
      "   75          1          1         0.99\n",
      "   76          0          0         0.00\n",
      "   77          0          0         0.01\n",
      "   78          0          0         0.10\n",
      "   79          0          0         0.18\n",
      "   80          0          0         0.01\n",
      "   81          1          0         0.55\n",
      "   82          1          1         0.83\n",
      "   83          0          0         0.01\n",
      "   84          1          1         0.98\n",
      "   85          0          0         0.49\n",
      "   86          0          0         0.00\n",
      "   87          1          1         0.93\n",
      "   88          0          0         0.00\n",
      "   89          0          0         0.02\n",
      "   90          0          0         0.08\n",
      "   91          1          1         0.99\n",
      "   92          1          0         0.52\n",
      "   93          0          0         0.02\n",
      "   94          0          0         0.03\n",
      "   95          0          0         0.03\n",
      "   96          0          0         0.07\n",
      "   97          1          1         0.95\n",
      "   98          0          0         0.04\n",
      "   99          0          0         0.02\n",
      "  100          1          1         0.72\n",
      "  101          0          0         0.00\n",
      "  102          0          0         0.05\n",
      "  103          1          1         0.87\n",
      "  104          0          0         0.20\n",
      "  105          0          0         0.02\n",
      "  106          1          0         0.60\n",
      "  107          1          1         0.96\n",
      "  108          1          0         0.56\n",
      "  109          1          1         0.98\n",
      "  110          0          0         0.00\n",
      "  111          0          0         0.00\n",
      "  112          0          0         0.00\n",
      "  113          0          0         0.01\n",
      "  114          1          0         0.56\n",
      "  115          0          0         0.00\n",
      "  116          1          1         0.98\n",
      "  117          1          1         0.99\n",
      "  118          1          1         0.79\n",
      "  119          0          0         0.01\n",
      "  120          0          0         0.01\n",
      "  121          1          1         0.99\n",
      "  122          0          0         0.02\n",
      "  123          0          0         0.06\n",
      "  124          0          0         0.21\n",
      "  125          1          1         0.90\n",
      "  126          0          0         0.01\n",
      "  127          0          0         0.24\n",
      "  128          0          0         0.11\n",
      "  129          0          0         0.02\n",
      "  130          0          0         0.00\n",
      "  131          0          0         0.15\n",
      "  132          0          0         0.11\n",
      "  133          1          1         0.98\n",
      "  134          0          0         0.01\n",
      "  135          1          1         0.98\n",
      "  136          0          0         0.02\n",
      "  137          1          1         0.79\n",
      "  138          0          0         0.01\n",
      "  139          0          0         0.40\n",
      "  140          0          0         0.04\n",
      "  141          0          0         0.01\n",
      "  142          0          0         0.09\n",
      "  143          0          0         0.05\n",
      "  144          0          0         0.00\n",
      "  145          0          0         0.13\n",
      "  146          1          1         0.97\n",
      "  147          1          1         0.99\n",
      "  148          1          1         1.00\n",
      "  149          0          0         0.37\n",
      "  150          0          0         0.02\n",
      "  151          0          0         0.01\n",
      "  152          0          0         0.00\n",
      "  153          0          0         0.02\n",
      "  154          0          0         0.01\n",
      "  155          1          1         0.97\n",
      "  156          0          0         0.08\n",
      "  157          1          1         0.84\n",
      "  158          0          0         0.01\n",
      "  159          0          0         0.31\n",
      "  160          0          0         0.01\n",
      "  161          0          0         0.03\n",
      "  162          1          1         0.84\n",
      "  163          0          1         0.47\n",
      "  164          0          0         0.00\n",
      "  165          1          1         0.97\n",
      "  166          0          0         0.18\n",
      "  167          0          0         0.03\n",
      "  168          1          1         0.99\n",
      "  169          0          0         0.03\n",
      "  170          1          1         0.90\n",
      "  171          1          1         0.93\n",
      "  172          0          0         0.14\n",
      "  173          0          0         0.30\n",
      "  174          0          0         0.01\n",
      "  175          1          1         0.82\n",
      "  176          1          1         0.99\n",
      "  177          0          1         0.50\n",
      "  178          0          0         0.21\n",
      "  179          0          0         0.30\n",
      "  180          0          0         0.03\n",
      "  181          1          1         0.93\n",
      "  182          0          0         0.00\n",
      "  183          0          0         0.06\n",
      "  184          0          0         0.04\n",
      "  185          0          0         0.12\n",
      "  186          0          0         0.05\n",
      "  187          0          0         0.02\n",
      "  188          0          0         0.37\n",
      "  189          0          1         0.42\n",
      "  190          0          0         0.00\n",
      "  191          1          1         0.81\n",
      "  192          0          0         0.01\n",
      "  193          1          1         0.99\n",
      "  194          0          0         0.01\n",
      "  195          0          0         0.03\n",
      "  196          0          0         0.07\n",
      "  197          0          0         0.10\n",
      "  198          0          0         0.06\n",
      "  199          0          0         0.01\n"
     ]
    }
   ],
   "source": [
    "# Ensure y_test is a numpy array to avoid indexing issues\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Print comparison of predicted and actual values\n",
    "print(\"\\nPredicted vs Actual values:\")\n",
    "print(f\"{'Index':>5} {'Predicted':>10} {'Actual':>10} {'Probability':>12}\")\n",
    "print(\"-\" * 40)\n",
    "for i in range(len(X_test)):  # Loop through the test set\n",
    "    print(f\"{i:>5} {y_pred[i]:>10} {y_test[i]:>10} {y_pred_prob[i][0]:>12.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a1f7466b-5381-4def-9631-1419a60b6a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Evaluate the model's performance\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "64df1df9-152d-4a0c-849a-e55cf0ae0d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.50%\n"
     ]
    }
   ],
   "source": [
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
